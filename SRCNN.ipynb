{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SRCNNDataset(Dataset):\n",
    "    def __init__(self, path, test, pad = 7, stride = 3, patch_size = (33, 19), sample = True):\n",
    "        super(SRCNNDataset, self).__init__()\n",
    "        \n",
    "        self.stride = stride\n",
    "        self.patch_size = patch_size\n",
    "        self.pad = pad\n",
    "        if test == True:\n",
    "            self.img_paths_var = sorted(glob.glob('./dataset/Set5/LR/bicubic' + path + '/*.png'))\n",
    "            self.img_paths_label = sorted(glob.glob('./dataset/Set5/HR/*.png'))\n",
    "            var = []\n",
    "            for img_path in self.img_paths_var:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = img/255\n",
    "                var.append(img)\n",
    "            label = []\n",
    "            for img_path in self.img_paths_label:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = img/255\n",
    "                label.append(img)\n",
    "        else:\n",
    "            self.img_paths_var = sorted(glob.glob('./dataset/T91/*.png'))\n",
    "            self.img_paths_label = sorted(glob.glob('./dataset/T91/*.png'))\n",
    "            var = []\n",
    "            label = []\n",
    "            for img_path in self.img_paths_var:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_height, img_width, _ = img.shape\n",
    "                for x in range(0, img_width - patch_size[0] + 1, stride):\n",
    "                    for y in range(0, img_height - patch_size[0] + 1, stride):\n",
    "                        left = x\n",
    "                        upper = y\n",
    "                        right = x + patch_size[0]\n",
    "                        lower = y + patch_size[0]\n",
    "                        # Crop the image\n",
    "                        cropped_img = img[upper : lower, left : right, : ]\n",
    "                        label.append(cropped_img/255)\n",
    "                        cropped_img_compressed = cv2.resize(cropped_img, dsize = (11, 11), interpolation = cv2.INTER_AREA)\n",
    "                        cropped_img = cv2.resize(cropped_img_compressed, dsize = (patch_size[0], patch_size[0]), interpolation = cv2.INTER_CUBIC)\n",
    "                        var.append(cropped_img/255)\n",
    "        sample = {\"image\": var, \"label\": label}\n",
    "        self.sample = sample\n",
    "    def __len__(self):\n",
    "        sample = self.sample\n",
    "        return len(sample[\"image\"])\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.sample\n",
    "        var = sample[\"image\"][index]\n",
    "        label = sample[\"label\"][index]\n",
    "        return var, label\n",
    "        \n",
    "dataset_train = SRCNNDataset(path = False, test = False)\n",
    "dataloader_train = DataLoader(dataset = dataset_train, batch_size = 256, shuffle = True)\n",
    "dataset_test = SRCNNDataset(path = '/X4', test = True)\n",
    "dataloader_test = DataLoader(dataset = dataset_test, batch_size = 256, shuffle = True)\n",
    "img1 = dataset_train.sample[\"image\"][22091]\n",
    "img2 = dataset_train.sample[\"label\"][22091]\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img1)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, f1, f2, f3, n1, n2, n3):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels= n3, out_channels= n1, kernel_size= f1, padding = 0)\n",
    "        self.conv2 = nn.Conv2d(in_channels= n1, out_channels= n2, kernel_size= f2, padding = 0)\n",
    "        self.conv3 = nn.Conv2d(in_channels= n2, out_channels= n3, kernel_size= f3, padding = 0)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        torch.nn.init.xavier_normal_(self.conv1.weight, gain= 0.001)\n",
    "        torch.nn.init.xavier_normal_(self.conv2.weight, gain= 0.001)\n",
    "        torch.nn.init.xavier_normal_(self.conv3.weight, gain= 0.001)\n",
    "        torch.nn.init.zeros_(self.conv1.bias)\n",
    "        torch.nn.init.zeros_(self.conv2.bias)\n",
    "        torch.nn.init.zeros_(self.conv3.bias)\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2, n3 = 64, 32, 3\n",
    "f1, f2, f3 = 9, 3, 5\n",
    "srcnn = SRCNN(f1, f2, f3, n1, n2, n3)\n",
    "srcnn.to('cuda')\n",
    "\n",
    "#Validation\n",
    "criterion = nn.MSELoss()\n",
    "def convert_rgb_to_y(img):\n",
    "    if type(img) == np.ndarray:\n",
    "        return 16. + (64.738 * img[:, :, 0] + 129.057 * img[:, :, 1] + 25.064 * img[:, :, 2]) / 256.\n",
    "    elif type(img) == torch.Tensor:\n",
    "        if len(img.shape) == 4:\n",
    "            img = img.squeeze(0)\n",
    "        return 16. + (64.738 * img[0, :, :] + 129.057 * img[1, :, :] + 25.064 * img[2, :, :]) / 256.\n",
    "    else:\n",
    "        raise Exception('Unknown Type', type(img))\n",
    "def test():\n",
    "        srcnn.eval()\n",
    "        psnr = 0\n",
    "        for idx in range(5):\n",
    "            inputs = dataset_test.sample[\"image\"][idx]\n",
    "            targets = dataset_test.sample[\"label\"][idx]\n",
    "            desired_target_width_size = targets.shape[0]\n",
    "            desired_target_height_size = targets.shape[1]\n",
    "            \n",
    "            #Resize the inputs\n",
    "            inputs = cv2.resize(inputs, dsize = (desired_target_height_size, desired_target_width_size), interpolation= cv2.INTER_CUBIC)\n",
    "        \n",
    "            #Apply the formation transforms\n",
    "            inputs = torch.tensor(inputs).to('cuda')\n",
    "            targets = torch.tensor(targets).to('cuda')\n",
    "            \n",
    "            #Crop the targets and change into the desired form\n",
    "            cropped_targets = targets.unsqueeze(0)\n",
    "            cropped_targets = cropped_targets.permute(0, 3, 1, 2)\n",
    "            cropped_targets = cropped_targets[ : , : , 7 : -7, 7 : -7]\n",
    "\n",
    "            #Change the input into the desired form\n",
    "            targets = targets.unsqueeze(0)\n",
    "            targets = targets.permute(0, 3, 1, 2)\n",
    "            #targets = targets/255\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            inputs = inputs.permute(0, 3, 1, 2)\n",
    "            #inputs = inputs/255\n",
    "\n",
    "            outputs = srcnn(inputs.float())\n",
    "            psnr_outputs = outputs * 255\n",
    "            psnr_cropped_targets = cropped_targets * 255\n",
    "            psnr_outputs = convert_rgb_to_y(psnr_outputs)\n",
    "            psnr_cropped_targets = convert_rgb_to_y(psnr_cropped_targets)\n",
    "            psnr_outputs = psnr_outputs / 255\n",
    "            psnr_cropped_targets = psnr_cropped_targets / 255\n",
    "            mse = (psnr_outputs - psnr_cropped_targets) ** 2\n",
    "            mse = mse.detach().cpu().numpy()\n",
    "            cropped = outputs.detach().cpu().numpy()\n",
    "            mse_max = np.max(cropped)\n",
    "            mse_value = np.sqrt(mse.mean())\n",
    "            psnr_picture = 20 * np.log10(mse_max / mse_value)\n",
    "            psnr += psnr_picture\n",
    "        return psnr / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "epochs = 100000\n",
    "conv1 = srcnn.conv1\n",
    "conv2 = srcnn.conv2\n",
    "conv3 = srcnn.conv3\n",
    "psnr_graph = []\n",
    "num_epoch = []\n",
    "number_of_backpropagation = 0\n",
    "t = 0\n",
    "srcnn.train()\n",
    "for epoch in range(epochs):\n",
    "    for batch_size , data in enumerate(dataloader_train, 0):\n",
    "        inputs, labels = data[0].to('cuda'), data[1].to('cuda')\n",
    "        optimizer = torch.optim.Adam([ {'params' : conv1.parameters(), 'lr' : 0.00001},\n",
    "                                       {'params' : conv2.parameters(), 'lr' : 0.00001},\n",
    "                                       {'params' : conv3.parameters(), 'lr' : 0.000001}])\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        labels = labels.to(torch.float32)\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        labels = labels.permute(0, 3, 1, 2)\n",
    "        optimizer.zero_grad()\n",
    "        output = srcnn(inputs)\n",
    "        cropped_labels = labels[:, :, 7:-7, 7:-7]\n",
    "        loss = criterion(output, cropped_labels)\n",
    "        loss.backward()\n",
    "        number_of_backpropagation = number_of_backpropagation + 1\n",
    "        optimizer.step()\n",
    "        if batch_size % 128 == 127:\n",
    "            print(f'[{epoch}, {batch_size:5d}] loss : {loss : 3f}')\n",
    "    psnr = test()\n",
    "    print(epoch, loss, \"PSNR : \", psnr) \n",
    "    psnr_graph.append(psnr)\n",
    "    num_epoch.append(epoch)\n",
    "    print(number_of_backpropagation)\n",
    "    if psnr > 32:\n",
    "        t = t + 1\n",
    "print(\"successful : \", t)\n",
    "plt.plot(num_epoch, psnr_graph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def convert_rgb_to_y(img):\n",
    "    if type(img) == np.ndarray:\n",
    "        return 16. + (64.738 * img[:, :, 0] + 129.057 * img[:, :, 1] + 25.064 * img[:, :, 2]) / 256.\n",
    "    elif type(img) == torch.Tensor:\n",
    "        if len(img.shape) == 4:\n",
    "            img = img.squeeze(0)\n",
    "        return 16. + (64.738 * img[0, :, :] + 129.057 * img[1, :, :] + 25.064 * img[2, :, :]) / 256.\n",
    "    else:\n",
    "        raise Exception('Unknown Type', type(img))\n",
    "srcnn.eval()\n",
    "psnr = 0\n",
    "psnr_picture = 0\n",
    "i = 5\n",
    "input_box, generated_box, output_box = [], [], []\n",
    "for idx in range(i):\n",
    "    with torch.no_grad():\n",
    "        inputs = dataset_test.sample[\"image\"][idx]\n",
    "        targets = dataset_test.sample[\"label\"][idx]\n",
    "        desired_target_width_size = targets.shape[0]\n",
    "        desired_target_height_size = targets.shape[1]\n",
    "\n",
    "        #Resize the inputs\n",
    "        inputs = cv2.resize(inputs, dsize = (desired_target_height_size, desired_target_width_size), interpolation= cv2.INTER_CUBIC)\n",
    "        \n",
    "        #Apply the formation transforms\n",
    "        inputs = torch.tensor(inputs).to('cuda')\n",
    "        targets = torch.tensor(targets).to('cuda')\n",
    "            \n",
    "        #Crop the targets and change into the desired form\n",
    "        cropped_targets = targets.unsqueeze(0)\n",
    "        cropped_targets = cropped_targets.permute(0, 3, 1, 2)\n",
    "        cropped_targets = cropped_targets[ : , : , 7 : -7, 7 : -7]\n",
    "\n",
    "        #Change the input into the desired form\n",
    "        targets = targets.unsqueeze(0)\n",
    "        targets = targets.permute(0, 3, 1, 2)\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        outputs = srcnn(inputs.float())\n",
    "    outputs_final = outputs.permute(2, 3, 1, 0)\n",
    "    targets_final = cropped_targets.permute(2, 3, 1, 0)\n",
    "    targets_final = targets.permute(2, 3, 1, 0)\n",
    "    output_size_height = outputs_final.shape[0]\n",
    "    output_size_width = outputs_final.shape[1]\n",
    "    target_size_height = targets_final.shape[0]\n",
    "    target_size_width = targets_final.shape[1]\n",
    "    outputs_final = outputs_final.view(output_size_height, output_size_width, 3)\n",
    "    targets_final = targets_final.view(target_size_height, target_size_width, 3)\n",
    "    outputs_final, targets_final = outputs_final.detach().cpu().numpy(), targets_final.detach().cpu().numpy()\n",
    "    \n",
    "    #inputs\n",
    "    inputs = dataset_test.sample[\"image\"][idx]\n",
    "    desired_input_size = inputs.shape[1]\n",
    "    desired_target_height_size = targets.shape[3]\n",
    "    desired_target_width_size = targets.shape[2]\n",
    "    inputs_final = cv2.resize(inputs, dsize = (desired_target_height_size, desired_target_width_size), interpolation= cv2.INTER_CUBIC)\n",
    "    \n",
    "    input_box.append(inputs_final)\n",
    "    generated_box.append(outputs_final)\n",
    "    output_box.append(targets_final)\n",
    "    \n",
    "    #plot\n",
    "    plt.subplot(i, 3, 1 + 3 * idx)\n",
    "    plt.imshow(input_box[idx])\n",
    "    plt.subplot(i, 3, 2 + 3 * idx)\n",
    "    plt.imshow(generated_box[idx])\n",
    "    plt.subplot(i, 3, 3 + 3 * idx)\n",
    "    plt.imshow(output_box[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_y(img):\n",
    "    if type(img) == np.ndarray:\n",
    "        return 16. + (64.738 * img[:, :, 0] + 129.057 * img[:, :, 1] + 25.064 * img[:, :, 2]) / 256.\n",
    "    elif type(img) == torch.Tensor:\n",
    "        if len(img.shape) == 4:\n",
    "            img = img.squeeze(0)\n",
    "        return 16. + (64.738 * img[0, :, :] + 129.057 * img[1, :, :] + 25.064 * img[2, :, :]) / 256.\n",
    "    else:\n",
    "        raise Exception('Unknown Type', type(img))\n",
    "srcnn.eval()\n",
    "psnr = 0\n",
    "psnr_picture = 0\n",
    "i = 5\n",
    "for idx in range (i):\n",
    "    with torch.no_grad():\n",
    "        inputs = dataset_test.sample[\"image\"][idx]\n",
    "        targets = dataset_test.sample[\"label\"][idx]\n",
    "        desired_target_width_size = targets.shape[0]\n",
    "        desired_target_height_size = targets.shape[1]\n",
    "\n",
    "        #Resize the inputs\n",
    "        inputs = cv2.resize(inputs, dsize = (desired_target_height_size, desired_target_width_size), interpolation= cv2.INTER_CUBIC)\n",
    "        \n",
    "        #Apply the formation transforms\n",
    "        inputs = torch.tensor(inputs).to('cuda')\n",
    "        targets = torch.tensor(targets).to('cuda')\n",
    "            \n",
    "        #Crop the targets and change into the desired form\n",
    "        cropped_targets = targets.unsqueeze(0)\n",
    "        cropped_targets = cropped_targets.permute(0, 3, 1, 2)\n",
    "        cropped_targets = cropped_targets[ : , : , 7 : -7, 7 : -7]\n",
    "        print(cropped_targets.shape)\n",
    "\n",
    "        #Change the input into the desired form\n",
    "        targets = targets.unsqueeze(0)\n",
    "        targets = targets.permute(0, 3, 1, 2)\n",
    "        #targets = targets/255\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        #inputs = inputs/255\n",
    "\n",
    "        outputs = srcnn(inputs.float())\n",
    "        psnr_outputs = outputs * 256\n",
    "        psnr_cropped_targets = cropped_targets * 256\n",
    "        psnr_outputs = convert_rgb_to_y(psnr_outputs)\n",
    "        psnr_cropped_targets = convert_rgb_to_y(psnr_cropped_targets)\n",
    "        psnr_outputs = psnr_outputs / 256\n",
    "        psnr_cropped_targets = psnr_cropped_targets / 256\n",
    "        mse = (psnr_outputs - psnr_cropped_targets) ** 2\n",
    "        mse = mse.detach().cpu().numpy()\n",
    "        cropped = outputs.detach().cpu().numpy()\n",
    "        mse_max = np.max(cropped)\n",
    "        mse_value = np.sqrt(mse.mean())\n",
    "        psnr_picture = 20 * np.log10(mse_max / mse_value)\n",
    "        print(sum(sum(sum(sum(outputs > 1)))))\n",
    "        psnr += psnr_picture\n",
    "        print(psnr_picture)\n",
    "        print(mse_value)\n",
    "    outputs_final = outputs.permute(2, 3, 1, 0)\n",
    "    targets_final = cropped_targets.permute(2, 3, 1, 0)\n",
    "    targets_final = targets.permute(2, 3, 1, 0)\n",
    "    print(targets_final.shape)\n",
    "    print(outputs_final.shape)\n",
    "    output_size_height = outputs_final.shape[0]\n",
    "    output_size_width = outputs_final.shape[1]\n",
    "    target_size_height = targets_final.shape[0]\n",
    "    target_size_width = targets_final.shape[1]\n",
    "    outputs_final = outputs_final.view(output_size_height, output_size_width, 3)\n",
    "    targets_final = targets_final.view(target_size_height, target_size_width, 3)\n",
    "    outputs_final, targets_final = outputs_final.detach().cpu().numpy(), targets_final.detach().cpu().numpy()\n",
    "    \n",
    "    #inputs\n",
    "    inputs = dataset_test.sample[\"image\"][idx]\n",
    "    desired_input_size = inputs.shape[1]\n",
    "    desired_target_height_size = targets.shape[3]\n",
    "    desired_target_width_size = targets.shape[2]\n",
    "    inputs_final = cv2.resize(inputs, dsize = (desired_target_height_size, desired_target_width_size), interpolation= cv2.INTER_CUBIC)\n",
    "    #inputs_final = cv2.cvtColor(inputs_final, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(inputs_final)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(outputs_final)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(targets_final)\n",
    "#centercrop\n",
    "print(\"psnr :\", psnr/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "srcnn_model = SRCNN(f1, f2, f3, n1, n2, n3)\n",
    "\n",
    "# Move the model to the GPU\n",
    "srcnn_model.to('cuda')\n",
    "\n",
    "# Create a dummy input tensor and move it to the GPU\n",
    "dummy_input = torch.randn((1, 3, 33, 33)).to('cuda')\n",
    "\n",
    "# Print the model summary\n",
    "summary(srcnn_model, input_size=(3, 33, 33), device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SRCNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
